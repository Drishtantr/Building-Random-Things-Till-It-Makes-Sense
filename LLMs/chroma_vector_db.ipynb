{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f51acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from pprint import pprint\n",
    "\n",
    "# Create document collection. Collections are where we store our embeddings,\n",
    "#  documents, and any additional metadata.\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "# collection = client.create_collection(\"all-my-documents\")\n",
    "\n",
    "collection = client.create_collection(\n",
    "      name=\"all-my-documents\",\n",
    "      metadata={\"hnsw:space\": \"cosine\"} # metadata is optional\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ba041",
   "metadata": {},
   "source": [
    "### 1. Embedding\n",
    "\n",
    "Embedding refers to converting the documents or texts into vectors (numerical representations) that can be used for similarity search. In this code, the embedding process is handled automatically by Chroma when we add documents to the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8008bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can store our text, and handle tokenization, embedding, and indexing automatically! \n",
    "# Chroma will also store the documents themselves. If the documents are too large to embed \n",
    "# using the chosen embedding function, an exception will be raised.\n",
    "\n",
    "\n",
    "# By default, Chroma uses the Sentence Transformers all-MiniLM-L6-v2 model to create embeddings.\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is a document about food\",\n",
    "        \"This is a document about animal's food\",\n",
    "        \"This is a document about cats and dogs\",\n",
    "    ],\n",
    "    metadatas=[{\"topic\": \"food\"}, {\"topic\": \"animal\"}, {\"topic\": \"animal\"}],\n",
    "    ids=[\"doc1\", \"docs2\", \"doc3\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4dfa8",
   "metadata": {},
   "source": [
    "In the collection.add method, the documents are passed to the collection, and Chroma uses the default Sentence Transformers all-MiniLM-L6-v2 model to create embeddings for these documents. This step transforms the text into vectors that can be used for indexing and querying.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc45b4",
   "metadata": {},
   "source": [
    "### 2. Indexing\n",
    "\n",
    "Indexing refers to organizing the embedded vectors in a way that allows for efficient similarity search. This is implicitly handled by Chroma when the documents are added to the collection.\n",
    "\n",
    "During the collection.add method call, Chroma not only embeds the documents but also indexes these embeddings. The metadata {\"hnsw:space\": \"cosine\"} provided during collection creation suggests that the HNSW (Hierarchical Navigable Small World) algorithm is used for indexing, which optimizes for cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc0688",
   "metadata": {},
   "source": [
    "### 3. Querying\n",
    "In the collection.query method, the provided query text is first embedded using the same model, and then Chroma searches the indexed vectors to find the top n_results most similar vectors to the query embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c552bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query asking about pizza\"],\n",
    "    n_results=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80376ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distances': [[0.5715243220329285, 0.7453498840332031]],\n",
      " 'documents': [['This is a document about food',\n",
      "                \"This is a document about animal's food\"]],\n",
      " 'embeddings': None,\n",
      " 'ids': [['doc1', 'docs2']],\n",
      " 'metadatas': [[{'topic': 'food'}, {'topic': 'animal'}]]}\n"
     ]
    }
   ],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deda05fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distances': [[0.5715243220329285]],\n",
      " 'documents': [['This is a document about food']],\n",
      " 'embeddings': None,\n",
      " 'ids': [['doc1']],\n",
      " 'metadatas': [[{'topic': 'food'}]]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query asking about pizza\"],\n",
    "    n_results=2,\n",
    "    where={\"topic\": \"food\"},\n",
    ")\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a14029",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "Embedding: Done in collection.add method where documents are converted into vectors.\n",
    "\n",
    "Indexing: Also done in collection.add method where the embedded vectors are organized for efficient similarity search.\n",
    "\n",
    "Querying: Done in collection.query method where the query text is embedded, and the indexed vectors are searched for the most similar results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
